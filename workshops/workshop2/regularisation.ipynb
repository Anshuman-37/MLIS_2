{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regularisation.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anshuman-37/MLIS_2/blob/main/workshops/workshop2/regularisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9lgu7n44eFs"
      },
      "source": [
        "**Regularisation**\n",
        "\n",
        "In this example you are given a dataset (MNIST) with a limited number of training examples (only 1000 compared to the usual 60,000). \n",
        "\n",
        "Your goal is to implement regularisation methods to achive the **lowest possible test loss using this dataset**. \n",
        "\n",
        "You should consider methods given in the lectures including:\n",
        "\n",
        "*   Data augmentation - ? \n",
        "*   Early stopping - ?\n",
        "*   L1/L2 penalty norms - Done\n",
        "*   Dropout - Done\n",
        "\n",
        "You are free to change the network architecture and model complexity, but the main purpose of the workshop is to investigate regularisation (next week you will look at CNN architectures in detail).  - Done\n",
        "\n",
        "You are also free to change the choice of optimiser, and other hyper-parameters such as the batch size.  - Done\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNviuTwum6vs"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARZRYjHQnE-0"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "from keras.regularizers import l1\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I-MxTxAnH2d"
      },
      "source": [
        "tf.random.set_seed(1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxO576eJnMXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f9a6de-a725-48b0-f78b-57d15bfd5a9e"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4F_HTQpnvSk"
      },
      "source": [
        "First load the MNIST dataset and add a channels dimension (channels last convention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twdc-t9FnN_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf43d35-7eaa-4e67-c3ca-ddfb57f7621c"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train[..., tf.newaxis].astype(np.float32)\n",
        "x_test = x_test[..., tf.newaxis].astype(np.float32)\n",
        "\n",
        "img_rows = x_train.shape[1]\n",
        "img_cols = x_train.shape[2]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEsWYkNz5Po7"
      },
      "source": [
        "Let's use a much smaller training dataset of 1000 examples so overfitting is more problematic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzt-HoIo4yks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6feb7ee2-d2ed-4b6b-b56c-85585defc1e9"
      },
      "source": [
        "n_train = 1000\n",
        "x_train = x_train[0:n_train, :]\n",
        "y_train = y_train[0:n_train]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2JSWYGKjsPh"
      },
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(15, 15))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(np.squeeze(img))\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDfQh4AfoBAH"
      },
      "source": [
        "Let's visualise several training examples - to do this we use the keras ImageDataGenerator. We rescale images by 1/255 to normalise them in the range (0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Refer this for why we should rescale the images \n",
        "# https://github.com/Arsey/keras-transfer-learning-for-oxford102/issues/1\n",
        "\n",
        "image_generator = ImageDataGenerator(rescale=1./255) \n",
        "data_gen = image_generator.flow(x_train, y_train, batch_size=32) \n",
        "sample_images, sample_labels = next(data_gen)\n",
        "plotImages(sample_images[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "ORY3aQeLH2yM",
        "outputId": "4ec9aa89-5e27-4e41-d61e-76709c28f893"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8bStvJVoVlj"
      },
      "source": [
        "One regularisation method to deal with over-fitting is data augmentation. The image generator can apply various transformations to data - here we apply a random rotation of upto 20 degrees and visualise the same training example with different augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz28zlncmIiP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "fa7d67c3-5ba4-423c-82f1-6596858903ee"
      },
      "source": [
        "image_generator = ImageDataGenerator(rescale=1./255,rotation_range=20) \n",
        "data_gen = image_generator.flow(x_train, y_train, batch_size=32) \n",
        "augmented_images = [data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAADZCAYAAADWkMBPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZiddXk38N+ZM5NJZrKSkAWyELIBYQ+7grtFqKIgikKriGC1In3dWqmtl33R1re++rbqpV0QNwrIUhGq0AgVRATZ15AEQiAhQEI2sk0yc855/+gfbb2875HJ9iT5fP798vyehzPn2e6c6/rWWq1WAQAAAKiytp19AAAAAAD9McAAAAAAKs8AAwAAAKg8AwwAAACg8gwwAAAAgMozwAAAAAAqrz0L39R2po5V+B3NbV5d+13+O+cV/O6cV7DtOa9g23Newbb3284rv8AAAAAAKs8AAwAAAKg8AwwAAACg8gwwAAAAgMozwAAAAAAqzwADAAAAqDwDDAAAAKDyDDAAAACAyjPAAAAAACrPAAMAAACoPAMMAAAAoPIMMAAAAIDKM8AAAAAAKq99Zx/AnqrWnn/0bVMnh1ljVHeY1VetT9dtPPl0fmAA7Hna6mHUPm7vdNPWqOFhVuvZEmaNJcvydXvjbQHgN/X3flWfuE+Y9Y0dEW+3dlO6bmP+k/mBsU35BQYAAABQeQYYAAAAQOUZYAAAAACVZ4ABAAAAVJ4BBgAAAFB5BhgAAABA5alR3Y5WfPj4MOsZXUu33XJgXNczaeyqMDtpbF7j8+PFh4TZyG8OC7Mhdy0Is8bal9N9llYrz+E31EeNCrPlpx8QZhvfsi5d990z7g+zK+bPCbMpX06XLfWFS8OssXp1vjHsII3XHhlmGyYMCrOVh+b3qyEHrgmzU6csCrMH10xM1139T3Gd+Khb4nUbK1bGizYb6T7hlWodf1iYbZg0JMxGPLgiX3hF/KxX2uJzsrEy2Q52A6vOjd+v1k/O71eb9+8Jswnj4nvZ0Xs/m6579/JpYdb27TFhNuLWhWHWWNXP8+Me/H7lFxgAAABA5RlgAAAAAJVngAEAAABUngEGAAAAUHkGGAAAAEDlGWAAAAAAladGdSvVR44Is5Mv+GWYHTc0rzs9tWt9vM/awOdOF+716zD7q0teG2Y333xUmE3/p+fSffYtzquH2D21dXWl+aLPxNVz7QfF1bz3HPt3YdZRq+fHVOJ6rc+OeTTM+l6VVy9+Ytmrw+yJT8fVlfX/iGtdYVtb9P74+3/y7AfD7OJxP0vXnVDPz/XQ2HifpZTyyBd6w+xj7zsrzOpfnRJmg3/+SLrPZk9csceurdYRVwX3nhRXzJdSyqL3JveOE24Msxd742fE5b1xdX0ppezbGVco/tOP3xxm067Mqxebj8yPwz24lpFdx6zz54XZO/e+N932NYOXh9nQts4BH9PqsbeF2Zf+7MQwu+GIY8Ns+nfiYy2llMbCuE58dz+X/QIDAAAAqDwDDAAAAKDyDDAAAACAyjPAAAAAACrPAAMAAACoPAMMAAAAoPLUqG6lnqOmh9mc7qvD7G3dG/tZefvMlsbUu8PsqxPuDrNrz1wQZpesPDvd54SvqFHdE9UGdaT5h0//aZj98cinwqxtJ1y2Omv5/8tX97kzzC79xtIw+/Fx08Ks8XJcJQsD8d7D4xrtz+0dV5p21Iam6zZazQEfU+bwzrjS7qoDvx9m7/n4OWHW9tDIdJ/N51/o/8CorKy+u+ek2WG29iP59fbmw74dZjM74ueqUgb+feptxfXd7z7noTB7xyEfSNdt/eS4MBt/XXzvbbyYVzrCtlSfPSvMXjcqrix9a1d+LjfLwKtSM6PaBofZ/xkfV7ue8u74XP7Yug+l+5z05SVh1urdkm67q/MLDAAAAKDyDDAAAACAyjPAAAAAACrPAAMAAACoPAMMAAAAoPIMMAAAAIDKM8AAAAAAKq99Zx/Arm7l7LhPeO/2vIt4oDa3esOsp9WXbtvbaobZxlYrzE7pivuErzvjiXSf667aJ8z6nluWbssurBl/n0opZXAt/h531Oph1ki+w1ujWeLj/cWmfNZ74uD4mP5w+NNhdsdNM8Js1bnT03025j+Z5uyZ6uPGhtnkzkfDbHudc5uTe1K2z1JKuaenEWZHd3aF2fcO+EGY/d75n073OfVrm8OssXp1ui0738u/f2iY9b5vZZh966B/Sded2dE94GOKrG1uSvNlffE9aXS9FmY3H35Zuu6l+x0eZt8b+aYwm/Kt+J7t3GBbW3XEqDAb37Fmu+yztxXfc7J7WX9WJM/Dx3bG71enveuOdN0H/3lcmDVWrOj/wHZhfoEBAAAAVJ4BBgAAAFB5BhgAAABA5RlgAAAAAJVngAEAAABUngEGAAAAUHlqVLfSy7PiWp3x9Q1htjSpxyqllGvWHRxmj63fN8xuuTverpRSxtwfz6xePmV9mF17zD+G2af2uSnd57s++bEwm/WFpLLupbjyjOprJbW820tWhVpKKdeuHxNm3/r4O8OsY31enzXsfy8Ns6un3Rxm35j80zA78kP/K93n9E88FYc74bOnGpqT41q14W33hFlWH7egN655K6WUX2yMK39/9EJc2djz5bhiu5RS1u8TP6Kc/rFbw+wTo+O62A+8Kz4fSynlhoffEGZDfvTrdFt2vrbe+Np38cz4entMZ8eA95nVDC/o7QmzU37yJ+m6438RP6/1nBXXSF51+KXpup/ca36YXfCRh8LspMYnw2zSd/Na78aLy9McftPa6fH3f3z95TB7rpHfr65L3q8eWjcpzH7+6Kx03TG/jK8hq14fXweueHX8fnXWqPyec8UXLgyzA/883m53qFj1CwwAAACg8gwwAAAAgMozwAAAAAAqzwADAAAAqDwDDAAAAKDyDDAAAACAylOjupVmXB7X9Zyx6FNh1ujM1+1eFleBjZ37bHw8S+9O123r6gqzQesPCbPvzTg+zP5qbFzNV0opMw5bEmZ9MyeGWU2N6q6tGVfLbY0r1+8dZl/8zrvTbSf+za/CrLOVfI9rtXTd9X96aJjd8L3hYfb27ri6+N4zv5Lu87Tb4gq+Idere9xTtW2M70kXz31XmF2yT/xd3LhsaLrPSTfH96vBN8Tfxc7yXLpu94TxYfb9iXHd6bvPvS/MTh8W10SWUso33/7aMDvgl/G1Z3eopdsdDL35kTBbcsnoMGt0xbWMpZRSr8X/3repFZ9zZz98bpjNunRDus/avKfDrO2u+Lt46ofiutNSSvngqT8Lsz8dvTDMjjsjPncefiG+B5ZSysjvJ+eH2m9+iyk3rA2z81+4KMx6h+XPa4NfSt6vbns+zGYuujddt627O8yGrJodZt+c8fow+9rEuek+jzhgcZitPWRymLXfuuvfr/wCAwAAAKg8AwwAAACg8gwwAAAAgMozwAAAAAAqzwADAAAAqDwDDAAAAKDyDDAAAACAymvf2Qewq6vdGfdiT3piVJi1NvWk6zY3bgyzvv4Pa0DrDr9lQZhd/dpjw+xP3nZHus+bDvi3MDvy0A+H2biH4k7lUkppbsg71Nm5su9aKaVc+alTwuwHQ+LZ6ohfLQmzict+lR/UQPvm+9mudtfDYfb3f3xWmJ162T+EWWctvzwvOTU+ppnXp5uyG2s9HZ8fB/y/LWFWa8bfp+ayp9J9Nnvy+9lA9b3wYphNuXFMmL3j8PPD7OFjrkj3+Y5DHgiz+46aE2adP12RrsuOkd13vv7oa8LstOMfS9ftadXC7JQ7PhpmM78YH0/jsXyf2V2n+fQzYTbjq5vSdb+74U1h9upz54fZ5ybcHGZnvmd8us/6fTPDrPFYvE/2XK374vNj/MLh8XZ9+VvSdnu/St5Jht4Wf8dvf83sMFt2xk3pPq+aFudHHXphmO17b/z5lVJK4+WX07wK/AIDAAAAqDwDDAAAAKDyDDAAAACAyjPAAAAAACrPAAMAAACoPAMMAAAAoPLUqG6tpF6xsXLVDjyQrddYG9fmTLtyc5jVT4vrxUopZXOrN8zWzow/v737qeGk4vqpHu38yb1xlmzXN9Aq1O0pOabBDz0bZl9bPSPMLhy1MN3lRa+aG2Y3d+8bZuqHd29pffGTT++4A9kWkvOqNj+ukex54uAwe/bI9ekuD+paFma3TjsuzMamq1IF3f8RV7O/uRZXupdSSv2BYWE289tPhlnjxeX9H9g21lieV/pOvbwrzP5gfPw5zHv718PspkN+kO7zrTMuCrMh8+rxhs1Gui57pl2h5vO/a6xZG2YzvxtnHWcM/Hl33dRmmLUau/555RcYAAAAQOUZYAAAAACVZ4ABAAAAVJ4BBgAAAFB5BhgAAABA5RlgAAAAAJWnRpX/0oord0o9rkr9xqpj0mX/eK9fh1n3/nF9UK2eVGuVUlp9fWlOxVWxDnU7aKxYGWaXfe/kMLvworxG9YIRC8Lsuje+OcyGXB+fj7CraK6P61CHPxVvd926uGK1lFJOG/pomH15TLxdW1dcTVlKP/W27BDjLo//tuWOuHq6lFLaVi8Os75+akt3uH7urX2LFofZgV+Ot33bAe8Is8tnXpXu88U58fPc9HvGhVnfc3GtMewyavE7VLMzfhX/zppj02Wz96vR01bF+9zUk667K/ALDAAAAKDyDDAAAACAyjPAAAAAACrPAAMAAACoPAMMAAAAoPIMMAAAAIDKU6PKf0mqtzqWx5V1V8ybky77+ZMeC7OuQb1hVp88MV03qwKDymg2wmjSt+eH2Q/PG5su+86hLwz4kGCXl9yvxv4yri6+6T2z02WzeuLeoXHVeNteo9J11ajufM116+Lw0SfybbfxsVRV3+Jnw2zxnceF2TP7d6TrTj5haZhtuDOusO1Uo8ruILlf1dfE94bLHz0mXfbi1z4YZkM64ver9sl5bXR2HagKv8AAAAAAKs8AAwAAAKg8AwwAAACg8gwwAAAAgMozwAAAAAAqzwADAAAAqDwDDAAAAKDy2nf2AVRB+5RJad5a+3IcNuNu3y1HTg+zts2N/JheSvrKX3wpjBovJ8e6FZpPPhNmvS8flm77dO/6MHvx+ZFhtld9Vf8HBruwxsr4O76m0ZVu21nrCLNWW23Ax8Tuq23w4DCrTY3vg7XNcZ98KaW01m0Is2ZyT2pt3pyuO1DNBYvCrKdvYrrt5lZfmHWujP/Np7VpU/8HBjtAfczoNK+1x4/+fS+8GGYTfhWfG+veG19bSinlvIl3hNk3289Mt2XXVZ+xf5rX1m8Ms+yaujl7v9qSv191LE/er5Yn71dr1qbrDlTz6SVxtuaIdNtn+raE2dIXR4XZAZ3b511xR/ILDAAAAKDyDDAAAACAyjPAAAAAACrPAAMAAACoPAMMAAAAoPIMMAAAAIDK261qVNNqqFcfGmYL3t3Px1CbEEbjp6wMs2PHPhxmd74wNd3limfHhFn3M+PDrOv5uNa1lFJGLowri9rumRdmrd64qmfKfivSfe5Vr4dZ11OD4g3XJFVH7NayGrjl75g54HVbA20X7We7YUvjernBNz8Qb5icG1tj1YHJOfev22WXbEu1+Au34Yxj0k23DI3/XWLDhHjdntlxZV1rbXKdLqV0rIr3OXhVvM9Ba/P71YhFcc1q+x3x/bXVF5+Ps0bGNZGllDK0rTPMOuK22NLa1JOuy56prSuuw65N2Tfdtmff4WG2YUJ8Tq6bkt+weibENZNDxsfPnn91yFVhdvzgvBK5s7Y6zC5+Y3z9OPDe+Hm3lFL6nn8hzdk2ap3xdbHnDfH71bNn5ZWmrUZc9TlrSvy3ffXou8Lsludnpft8cnH8He96ZlyYDX2un/erBfENonbfE2GWvV+NnRq/Y5ZSysjkZwiDFybVxmuWpuvuCvwCAwAAAKg8AwwAAACg8gwwAAAAgMozwAAAAAAqzwADAAAAqDwDDAAAAKDydqsa1eYxs8Os58/WhNnTh1434H2ubsS1pKPqcX1WmXBvvvARAzueh7fkVW5/89xbwuze2+eE2ci4Aah8ZPK16T5HtA0Js7beeLvm6rh2i4pI6h6Xf/j4dNN1U+NKqmNOiL9w10z5uzCrJ8dTSiltycy2LelKrdfyWW92HVjY15FuGzm4I6/sKiWu0Ru1IK8uY+drGzYszJZ94JAwe9/5N6Xr9jTj79uRXYvD7E1D4hrVrZGdO8/3rU+3vW79gWH27afi68uqFXH95F+O+cd0n83SDLNWchloboyvAeze6qP3CrPnzjkgzF4+KHkAKqUcdsCzYfbnE38WZm8Ykl//N7fi/W5sxllaMVwb2H2ulFI++oZ/D7MfzPu9dNsJN8X3wb7F8efHK9P7qoPDbOin40rO+TNuHPA+N7bietGuWvx3/+yYuGK7lFJKfHtNPbAlvjeUUsrfLDklzObdclSY7fV4fL6+f7/88xudvF+1J7ek5qr4nXhX4RcYAAAAQOUZYAAAAACVZ4ABAAAAVJ4BBgAAAFB5BhgAAABA5RlgAAAAAJVngAEAAABUXvvOPoBXoj57VprP+8O4o/q2g76RbDk0XbfRirt/R9W70m13tEMHDU7zf55yc5itOvuGMMvajyfU4x7iUkq5fN3YMBu1sC/MWn1xRjWs+KPjwmzuZ/423XZwrR5mQ5KO7ypetoa3xefdnOx/ZTt57o2tMJt5bS3fuBVvyytQyz/nvsOnh9l7Pzg3zC4a9WS6br02sH+XaOyEP/uE9vzee8GIxWF2zhELwqw3uWePSM7VUkq5b3P8+XW/kN0J2ZXVx8XPKaWUsnHOlDB75q3xuX7jW/5vmM0elD87bS+dtY44q8fZ9nLByMfD7OBPLkm3/dCR7w+zmRc8O9BD2uPUjjo4zRefG1/7/mP/q5Mt8+94b6sRZl3pc+COd8Sg/N76vf3jd6gVU+L3mfz9Kv8MLl+3T5iNeDr+bFu9W9J1dwV+gQEAAABUngEGAAAAUHkGGAAAAEDlGWAAAAAAlWeAAQAAAFSeAQYAAABQedXrI0xsmjQ8zd985CNhNrmfurbMlev3DrMvP/GmMFvzUrzPjq7edJ8nTn0qzD6/z01hNrGf/8+utriSJ8u2xpM948Ksd0g8Q9s5BWO8Eu/88K1hNqpt4H/BrAoyqzXeWZplYB2UbaWfStMBOu+E28PsV/tOS7ftW/rctj6cPVJ9Zv45Lzg7riu8ftRj8br9VMst7VsfZtesi6vyHlo3Kcy663nl2sHdS8PstKHzw6y/GtXs/Bhai2vTs9Oqv5rZRlJqt/LgeOFh6apUQlJtvPL38vN1yDnPh9k/7P9vYXZAR/I93U6eT64BpZTylZdODLP56+LnteEdPWH2g/1+nu5zYzO+hnx++fFhdtaou9N1T59zX5g9mlVZqwv/HzaN70rz02ffE2YT6vGzXn/POJe9HJ93f//I68Jsy8q4DrvWHVeWllLKcdOfDrMvTIyrUCe258+0WT3xxPbtU0/8yMb4vt3aPo+XleEXGAAAAEDlGWAAAAAAlWeAAQAAAFSeAQYAAABQeQYYAAAAQOUZYAAAAACVt0vVqPbsVU/zd+x1/3bZ7yUPnxJmXXPjGrh9V8V1bMN/8Wy6z+c3x/+vH5j90TBbdHpcLVRKKQcfFdcH/fWUfw2zAwflFUuZWYPj+rEbhiY9P23537s0GwM8Il6J1e+PK84+ttdXw6xey7+LmY8tOzrM5t4YZ+PuzuuJB899IMxafXH1Vs9bj0nXff5V8Xe1Pi2utHv4hO+EWUct//5ndbKfGf14mF1wzZh03edOjGs6W715nSb/pTks//53j90QZltTaf2v62aH2d//7OQw2/ve+Fq810Or030+OS+uJPzxfseG2ZLTxqfr9h27Lsw+clBcFXzhqGfSdTNT2jeGWf2A+HjaJ01M1+1bElfNsmPUp08Ns9Vvif/upZRy98E/GuBe438n/OH6EemWf/HAaWG29w/jSseh18fVoqWUsuK8+B5af9tLYXbxgXFdbCn5/aqeVJr+aO5xYXbHQ/H1o5RSOtfEz4FdIxaEWWPN2nTdPc2m0fnfL6+zjbftr2L+7x6Oq1JH3tQdZoPWJ+9XP8+v/8lXplxw8IVhtuiMvBL5iDlPhtkXJ18fZlPbB/6sPG3w8jC7vTv5jUJWMVzKLlEz7BcYAAAAQOUZYAAAAACVZ4ABAAAAVJ4BBgAAAFB5BhgAAABA5RlgAAAAAJVXuRrVWkdcH9foyGtfXjckrisspWOAR5RXHf7trIPC7Jbls8Js6eTp6T6byeFu2D+uijx69sJ03RNGPRVmI9viWqJMVudYSim/3x3XqH7ujXGV4LhbJqXr9i1anOZsG80BXiX6+15kbvj1EWE2+d647nTLiLwKrLMR92etf1dc5bbsLXk964VH/yzORsXnZFuJr2n9fX6H3vUHYfaFQ+PKrtPH3Juu+/X64WHWyj8G/ptGd37PmTgyrj/bmnNnRucLYTZ62qowW9E2Ksx6u+OslFK6ZsTn60uHxf9OMuaY+FhLKeWcyXF132u6sntdXPt93+b+qoDjZ5CvHH51mH3inPPSVSf+tRrVnW51XJ15yZxbtssuP7cirjW++oevSbcdOy++Xw279Ykw63l9fA0vpZSNb4yflb80M65KPXRQfDyNVv58ftna/cJs9CNxZePI6x9J121uiJ8hk7bMPVJbd1xL2tud//1mdWT3pPy5KzPvxO+E2bcOnRJmP11+cJg9OyV+9yqllEbShrpx//j+cOyBcS1vKaXMGRHXt45Mfi6QPQfWa/nvDE4bOj/MvnRCfAaMmTsuXbfv+fzeXAV+gQEAAABUngEGAAAAUHkGGAAAAEDlGWAAAAAAlWeAAQAAAFSeAQYAAABQeQYYAAAAQOW17+wD+E2tvt4w2+uxdem2r3noPWF21+HXDPiYOmpxx/GnRj8eZp8Y/WiYvThzc7rPcfW4qLiz1hFmLzXiTuxSShlTj3ugG62uMOttxX3CR9z9h+k+v3vEZWH254f9JMyu3HBkui47X6PE/e1b44nTvhFmK34/Pne6++nMfvyLg8PssEG/CrOhbfF2pZTSaGUd6Xm/euTZvo1pvvel8fn69Y3vCrNNe8fXj1JKGbrl3vzA+J20bY6vmaWUMmZwfK1uJudV1hlfSiknd8XnxxuOuCLe5xHxd3jFafn9alAtPqbRbUPCbH0rX7ejxPfezlp8Tm5uxc8RH3787HSfq9YMDbPXTV8QZoPyxxMqYNOcqWG2rvFYP1uvHdA+73xp/wFtV0opS0+Oz8l9LhgdZl+Y8e103RMH94VZPb2HDgqT1Y38fvWl208Ns4NuWxpmfRvyZ1p+d83ksxx/55p025Puf1+Y3T3nXwZ8TJkPjlgUZu8bvjDMVl0Uf79LKWVMW/w9rif3slWN/H41ph7f60qJ71crm5vC7OQHPpDu8zuHfjfMPn7izWH2k9UT0nV3BX6BAQAAAFSeAQYAAABQeQYYAAAAQOUZYAAAAACVZ4ABAAAAVJ4BBgAAAFB5latRLa24Pq72eFypU0op7ZceEmbHf/CMMLto/1vTdc8atjrMsorVklTATW7PqwwHKqtJLSWvl3tgczzP+oun3x5m476RV0yeP/OiMNuwT7zdfi/GtZbsOF0vxXWQqxpxNnQrri5ZVfCEenbO5Y6L24lLVhG3vTy4Ja77uvAzn0y3HXbTPXHYTP4u/R4V28RdD6fx0kuODrMrvhJXcJ89bPmADym7XzVacX3chHpc2dufrJZxRC2rncvriVcn1XOnP35OmHV8N66fLKWUGU/EdYKLxhwQZvsseCZdNy/2Y0do3xD/Ff558avSbc877NoB7fOKmVeG2YgD8menrL4+q3ts6+ffJuvpc+vAjufq9dPTbQ/66+fDrG9JXKPKjtGa91SaD730sDA7cP15YXb27OQ5pZTy2THxfTL7Hncm95UJ9YG/X2U15XlNav5+dffm+N3s80++M8yG/eOIdJ/vnf3xMNsyIn6fntqz679f+QUGAAAAUHkGGAAAAEDlGWAAAAAAlWeAAQAAAFSeAQYAAABQeQYYAAAAQOVVr0Y10dy4Mc27r707DpMGrMvKlHTd7088IczWnDApzFYcHtfxDDtkZbrPj0y/PczOG/FCmK1NquVKKeVPlr45zO66Ka6h3e+aVWHWfPS+dJ/j7x8VZrWuuJZI7Vw1dN14f5i9rxVXOF3z9a+m645uyyupqiSrcyyllL4S18s9tCXe7i/P/ECYDbsvuZ6VklZOU32D5z4UZt8//61h9rXpefXihonxfWfTvvFVddQ+a8Ps6PHPpvt8y6hHwuzUrnjdvIa8lOca8T3/9Vd9KsymXh/fB9vvfTDdZ7OnJ9422c79qvoGLY2fY1Y8nnS6l1J6D42v8dn3uL9q+0x/58dA/XB9XM342fveHmbDfh7XKY+/flG6z74XlvR/YOw0rc2b03zI9b8Os2nXx9vdVfJK07d1nxRmG183O8yWHxVfjTsOX53u86Ozbguzc4fH39PVzfjeUEopf/R0fO48MXdGmO137Uth1lyY36+m3Bu/X5WO+LPfHe5XfoEBAAAAVJ4BBgAAAFB5BhgAAABA5RlgAAAAAJVngAEAAABUngEGAAAAUHkGGAAAAEDl1VqtVhi+qe3MOGSnqY8bG2brj9sv3XbQ2rj9t+Oe+WHW3LCh3+Pa081tXl37Xf673eq8aot76tu64874UkopzWacNRphlF2zsu1KKaXVTLZt5tuyc+yR59Ueoj5zWpr3TB4ZZoMfXBxmjZdWDvSQ9hjOq/9p09uPSfMDL34kzP5i/Nwwm9g+NMxWNzam+3zPwjPD7Jnbp4TZpH/Pn9dqdz6U5gyc82rX1r7vPmG29vhJ6bZdy3rCrH5/8n7VE2/Hf/pt55VfYAAAAACVZ4ABAAAAVJ4BBgAAAFB5BhgAAABA5RlgAAAAAJVngAEAAABUXvvOPgBeucaLy8NsyPVx1p+k1BJ+u6R6tLlu3Q48EGBX01jwVJp3LEi23cbHwp6t68b703zJ/Klhdsopnw6zYUviJ6uhV9+dH1TruTCaXOIMGJi+55aFWfc1cdYf71fbnl9gAAAAAJVngAEAAABUngEGAAAAUHkGGAAAAEDlGWAAABzc/3wAAAD2SURBVAAAlWeAAQAAAFSeGlUAAPZYrb6+NG/MWxhmE5IMgG3PLzAAAACAyjPAAAAAACrPAAMAAACoPAMMAAAAoPIMMAAAAIDKM8AAAAAAKs8AAwAAAKg8AwwAAACg8gwwAAAAgMozwAAAAAAqzwADAAAAqDwDDAAAAKDyDDAAAACAyjPAAAAAACrPAAMAAACoPAMMAAAAoPIMMAAAAIDKM8AAAAAAKs8AAwAAAKg8AwwAAACg8gwwAAAAgMqrtVqtnX0MAAAAACm/wAAAAAAqzwADAAAAqDwDDAAAAKDyDDAAAACAyjPAAAAAACrPAAMAAACovP8PdCSrz5BOsscAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x1080 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIE6-wlA3J4h"
      },
      "source": [
        "Define a basic CNN with 32 convolutional filters using a 3x3 kernel, followed by a dense fully connected layer of 128 units and an output layer of 10 units with softmax activation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKolHZQUL8-4"
      },
      "source": [
        "class BasicCNN(Model):\n",
        "    def __init__(self):\n",
        "        super(BasicCNN, self).__init__()\n",
        "        self.conv1 = Conv2D(128, 3, activation='relu')\n",
        "        self.polling1 =MaxPooling2D((2, 2), strides=(2, 2))\n",
        "        self.conv2 = Conv2D(64, 3, activation='relu')\n",
        "        self.polling2 =MaxPooling2D((2, 2), strides=(2, 2))\n",
        "        self.flatten = Flatten()\n",
        "        self.d1 = Dense(128, activation='selu',kernel_regularizer=l1(0.05), bias_regularizer=l1(0.05))\n",
        "        self.drp_out = Dropout(0.25)#input_shape=(128,))\n",
        "        self.d2 = Dense(64, activation='selu',kernel_regularizer=l1(0.05), bias_regularizer=l1(0.05))\n",
        "        self.drp_out2 = Dropout(0.25)\n",
        "        self.d3 = Dense(10, activation='softmax')\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.polling1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.polling2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.d1(x)\n",
        "        x = self.drp_out(x)\n",
        "        x = self.d2(x)\n",
        "        x = self.drp_out2(x)\n",
        "        return self.d3(x)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuhNDi134B2G"
      },
      "source": [
        "Main training routine - uses the more detailed Gradient Tape API to iterate over the dataset and update the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZH8jdqKohiU"
      },
      "source": [
        " def trainer(cls, train_image_generator, test_image_generator, \n",
        "            verbose=False, batch_size=32, max_epochs=5):\n",
        "     #New varaiables to append train and test loss\n",
        "  tr_loss = []\n",
        "  te_loss = []\n",
        "  model = cls()\n",
        "\n",
        "  train_data_gen = train_image_generator.flow(x_train, y_train, \n",
        "                                              batch_size=batch_size) \n",
        "\n",
        "  test_data_gen = test_image_generator.flow(x_test, y_test, \n",
        "                                              batch_size=batch_size) \n",
        "\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='train_accuracy')\n",
        "  tr_loss.append(train_loss)\n",
        "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='test_accuracy')\n",
        "  te_loss.append(te_loss)\n",
        "  \n",
        "\n",
        "  @tf.function\n",
        "  def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = model(images, training=True)\n",
        "      loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_loss(float(loss))\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "  @tf.function\n",
        "  def test_step(images, labels):\n",
        "    predictions = model(images, training=False)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "    test_loss(float(t_loss))\n",
        "    test_accuracy(labels, predictions)\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    # Reset the metrics at the start of the next epoch\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "    #early_stopping = EarlyStopping(monitor='test_loss', patience=2)\n",
        "    batches = 0\n",
        "    for images, labels in train_data_gen:\n",
        "      train_step(images, labels)\n",
        "      batches += 1\n",
        "      if batches >= len(x_train) / batch_size:\n",
        "        break\n",
        "\n",
        "    batches = 0\n",
        "    for images, labels in test_data_gen:\n",
        "      test_step(images, labels)\n",
        "      batches += 1\n",
        "      if batches >= len(x_test) / batch_size:\n",
        "        break\n",
        "\n",
        "    if verbose:\n",
        "      template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "      print(template.format(epoch+1,\n",
        "                            train_loss.result(),\n",
        "                            train_accuracy.result()*100,\n",
        "                            test_loss.result(),\n",
        "                            test_accuracy.result()*100))\n",
        "  \n",
        "  return test_loss.result().numpy(), tr_loss, te_loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBSBEZftgDsL"
      },
      "source": [
        "Baseline run with no regularisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkemC6SvTLOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e842acbf-810d-4ed3-968b-baa7f8d7db4b"
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "epochs = 15\n",
        "final_test_loss ,train_Loss , test_loss = trainer(BasicCNN, train_image_generator, test_image_generator, verbose=True, max_epochs=epochs)\n",
        "print('Final test loss:', final_test_loss)\n",
        "epochs = np.arange(1,9)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.4119194746017456, Accuracy: 54.400001525878906, Test Loss: 0.6314666867256165, Test Accuracy: 78.72999572753906\n",
            "Epoch 2, Loss: 0.4092411398887634, Accuracy: 86.0999984741211, Test Loss: 0.2920588254928589, Test Accuracy: 91.27999877929688\n",
            "Epoch 3, Loss: 0.2736033499240875, Accuracy: 92.4000015258789, Test Loss: 0.27283647656440735, Test Accuracy: 91.54999542236328\n",
            "Epoch 4, Loss: 0.19081424176692963, Accuracy: 94.4000015258789, Test Loss: 0.19343146681785583, Test Accuracy: 94.05999755859375\n",
            "Epoch 5, Loss: 0.13763809204101562, Accuracy: 95.5999984741211, Test Loss: 0.1903229057788849, Test Accuracy: 93.75\n",
            "Epoch 6, Loss: 0.08859603106975555, Accuracy: 97.69999694824219, Test Loss: 0.1776835024356842, Test Accuracy: 94.44000244140625\n",
            "Epoch 7, Loss: 0.11402160674333572, Accuracy: 96.0, Test Loss: 0.1799110472202301, Test Accuracy: 94.27999877929688\n",
            "Epoch 8, Loss: 0.0654933899641037, Accuracy: 98.29999542236328, Test Loss: 0.17500005662441254, Test Accuracy: 94.6300048828125\n",
            "Epoch 9, Loss: 0.058131035417318344, Accuracy: 98.4000015258789, Test Loss: 0.16070738434791565, Test Accuracy: 95.09000396728516\n",
            "Epoch 10, Loss: 0.03352230414748192, Accuracy: 99.19999694824219, Test Loss: 0.15806367993354797, Test Accuracy: 95.31000518798828\n",
            "Epoch 11, Loss: 0.03187592327594757, Accuracy: 99.19999694824219, Test Loss: 0.16355939209461212, Test Accuracy: 95.25\n",
            "Epoch 12, Loss: 0.027789296582341194, Accuracy: 99.19999694824219, Test Loss: 0.15484274923801422, Test Accuracy: 95.54000091552734\n",
            "Epoch 13, Loss: 0.015826059505343437, Accuracy: 99.80000305175781, Test Loss: 0.1671258807182312, Test Accuracy: 95.27999877929688\n",
            "Epoch 14, Loss: 0.015393061563372612, Accuracy: 99.69999694824219, Test Loss: 0.15503308176994324, Test Accuracy: 95.68000030517578\n",
            "Epoch 15, Loss: 0.00928441621363163, Accuracy: 99.9000015258789, Test Loss: 0.14935436844825745, Test Accuracy: 95.8800048828125\n",
            "Final test loss: 0.14935437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx1vid62esyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f7ae2cf-a04b-4cf9-cb5e-78c496a496b1"
      },
      "source": [
        "# def plot_metric(history, metric):\n",
        "#     train_metrics = history.history[metric]\n",
        "#     val_metrics = history.history['val_'+metric]\n",
        "#     epochs = range(1, len(train_metrics) + 1)\n",
        "#     plt.plot(epochs, train_metrics)\n",
        "#     plt.plot(epochs, val_metrics)\n",
        "#     plt.title('Training and validation '+ metric)\n",
        "#     plt.xlabel(\"Epochs\")\n",
        "#     plt.ylabel(metric)\n",
        "#     plt.legend([\"train_\"+metric, 'val_'+metric])\n",
        "#     plt.show()\n",
        "\n",
        "# plot_metric(history,test)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 28, 28, 1)\n",
            "(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model\n",
        "model = Sequential([\n",
        "                    Conv2D(filters=128,kernel_size=(3,3),activation='relu',padding='same'),#,input_shape=(28,28,1)),\n",
        "                    MaxPooling2D(pool_size = (2,2) ,strides = 2),\n",
        "                    Conv2D(filters=64,kernel_size=(3,3),activation='leaky_relu',padding='same'),#,input_shape=(28,28,1)),\n",
        "                    MaxPooling2D(pool_size = (2,2) ,strides = 2),\n",
        "                    Flatten(),\n",
        "                    Dense(units=128,activation='elu'),\n",
        "                    Dropout(0.25),\n",
        "                    Dense(units=64,activation = 'elu'),\n",
        "                    Dropout(0.25),\n",
        "                    Dense(units =10,activation = 'softmax')\n",
        "\n",
        "]) "
      ],
      "metadata": {
        "id": "MUQ2Ax9h0P2F"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metric(history, metric):\n",
        "    train_metrics = history.history[metric]\n",
        "    val_metrics = history.history['val_'+metric]\n",
        "    epochs = range(1, len(train_metrics) + 1)\n",
        "    plt.plot(epochs, train_metrics)\n",
        "    plt.plot(epochs, val_metrics)\n",
        "    plt.title('Training and validation '+ metric)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0QB-8qoIdrg7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}